# Clustering {#clus}

L'objectif des méthodes de classification automatique est de regrouper des observations qui se ressemblent sur un ensemble multidimensionnel de caractéristiques.

insérer image

Dans ce chapitre nous examinons deux familles de méthodes qui le distingue par la procédure de calcul : hierarchique d'une part, non hiérarchique de l'autre. On garde pour le chapître suivant l'étude des modèles de décisions qui ont une longue et riche histoire en marketing et ont préparé le développement de certains modèles de machine learning.

## Les méthodes hiérarchiques ascendantes

Elles trouvent leur origine en biologie où dès les années 1930 Sokal et Sneath[@sneath_numerical_1973] ont proposé des méthodes pour analyser l'évolution des espèces. L'idée réside dans la comparison de specimens sur la base d'un certains nombre de caractéristiques, d'abord des caractères phénotypiques, puis dans ce domaine en s'appuyant sur les caractéristiques génétiques. Nous n'entrerons pas dans une discussion plus approfondis mais signalons que ces choix déterminent des méthodes et des hypothèses très différentes et largement débattues (cladistique etc)

Prenons le cas de différences phénotypiques et le tableau suivant.

tableau

Le but du jeu est de regrouper successivement les spécimens en fonction de leur ressemblance. L'algorithme consiste simplement à 1) calculer toutes les ressemblances deux à deux et 2) à fondre en une classe les deux éléments qui se ressemble le plus. On réitère l'opération jusqu'à ce qu'on obtienne plus qu'une classe.

Le résultat est une arborescence dont chaque noeud représente un regrouppement de classe à un certain niveau de distance.


figure

Leurs variétés dépend de deux paramètres :

 * le choix de la mesure de dissimilarités : Une distance euclidienne ? Son carré ? Une distance binaire comme l'indice de Jaccard?
 * le choix de la méthode d'agrégation : que choisit-on pour calculer la distance entre deux classes A et B : la plus grande des distances entre les éléments de A et ceux de B ? La plus petite ? La distance moyennes, la médiane ? 
 
 
### Mise en oeuvre 

Une segmentation sur la base des avantages recherché dans le cadre de la campagne présidentielle. 

Les données : 12 domaines, codage oui-non



```{r 0603}

foo<- foo1 %>% 
  select(matches("V_.*"))

M = cor(foo)
M
corrplot(M, method="circle", order="hclust") 

hr <- hclust(as.dist(1-M), method="ward") # Clusters rows by Pearson correlation as distance method.
plot(hr)
```



### Forces et limites

 * forces : graphiques, complète
 * limites : petite population
 
 

## Les méthodes non-hiérarchiques

La première d'entre elles est la méthode k-means dont le principe est très simple : plutôt que de calculer 


### principe
### Application
### Forces et limites

## Autres méthodes

